---
title: "Accessing patent data with the patentsview package"
name: patentsview
author:
  - name: Chris Baker
    url: http://github.com/crew102
date: '2017-09-12'
layout: post_discourse
tags:
  - R
  - Patents
  - PatentsView
  - Package
  - API
  - USPTO
  - Review
  - Onboarding
  - Community
categories: blog
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

> This is the ropensci [blog post](https://ropensci.org/blog/2017/09/19/patentsview/) from 2017-09-12 that announced the creation of the original patentsview package, edited to work with the new version of the R package and API.


## Why care about patents?

**1. Patents play a critical role in incentivizing innovation, without which we wouldn't have much of the technology we rely on everyday**

What does your iPhone, Google's PageRank algorithm, and a butter substitute called Smart Balance all have in common? 

<span> <!-- These are open source images taken from: https://pixabay.com/ -->
<img src="../reference/figures/2017-09-12-patentsview-iphone.png" width="15%">
<img src="../man/figures/2017-09-12-patentsview-google.jpg" width="25%">
<img src="../man/figures/2017-09-12-patentsview-butter.png" width="25%">
</span>

...They all probably wouldn't be here if not for patents. A patent provides its owner with the ability to make money off of something that they invented, without having to worry about someone else copying their technology. Think Apple would spend millions of dollars developing the iPhone if Samsung could just come along and [rip it off](http://www.reuters.com/article/us-apple-samsung-elec-appeal-idUSKCN1271LF)? Probably not. 

**2. Patents offer a great opportunity for data analysis**

There are two primary reasons for this:

  - **Patent data is public**. In return for the exclusive right to profit off an invention, an individual/company has to publicly disclose the details of their invention to the rest of the world. [Examples of those details](https://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=11&f=G&l=50&co1=AND&d=PTXT&s1=dog&OS=dog&RS=dog) include the patent's title, abstract, technology classification, assigned organizations, etc.
  - **Patent data can answer questions that people care about**. Companies (especially big ones like IBM and Google) have a vested interest in extracting insights from patents, and spend a lot of time/resources trying figure out how to best manage their intellectual property (IP) rights.  They're plagued by questions like "who should I sell my underperforming patents to," "which technology areas are open to new innovations," "what's going to be the next big thing in the world of buttery spreads," etc. Patents offer a way to provide data-driven answers to these questions.

Combined, these two things make patents a prime target for data analysis. However, until recently it was hard to get at the data inside these documents. One had to either collect it manually using the official [United States Patent and Trademark Office](https://en.wikipedia.org/wiki/United_States_Patent_and_Trademark_Office) (USPTO) [search engine](https://ppubs.uspto.gov/pubwebapp/), or figure out a way to download, parse, and model huge XML data dumps. Enter PatentsView.

## PatentsView and the `patentsview` package

[PatentsView](https://datatool.patentsview.org/#viz/relationships) is one of USPTO's new initiatives intended to increase the usability and value of patent data. One feature of this project is a publicly accessible API that makes it easy to programmatically interact with the data. A few of the reasons why I like the API (and PatentsView more generally):

* An API key is now required (request one [here](https://patentsview.org/apis/keyrequest)) and throttling is imposed (handled by the new version of the R package) at 45 requests per minute.
* The project offers [bulk downloads of patent data](https://patentsview.org/download/data-download-tables) on their website (in a flat file format), for those who want to be closest to the data. 
* Both the API and the bulk download data contain disambiguated entities such as inventors, assignees, organizations, etc. In other words, the API will tell you whether it thinks that John Smith on patent X is the same person as John Smith on patent Y.[^1]  

The `patentsview` R package is a wrapper around the PatentsView API. It contains a function that acts as a client to the API (`search_pv()`) as well as several supporting functions. Full documentation of the package can be found on its [website](https://ropensci.github.io/patentsview/index.html).

## Installation

You can install the stable version of `patentsview` from r-universe:

```{r, eval = FALSE}
options(repos = c(
   patentsview = 'https://mustberuss.r-universe.dev/',
   CRAN = 'https://cloud.r-project.org'))

install.packages('patentsview')
```

Or  from GitHub:

```{r eval = FALSE}
if (!require(devtools)) install.packages("devtools")

devtools::install_github("mustberuss/patentsview@api-redesign")

```

## Getting started

The package has one main function, `search_pv()`, that makes it easy to send requests to the API. There are two parameters to `search_pv()` that you're going to want to think about just about every time you call it - `query` and `fields`. You tell the API how you want to filter the patent data with `query`, and which fields you want to retrieve with `fields`.[^2] 

### `query`

Your query has to use the [PatentsView query language](https://patentsview.org/apis/api-query-language), which is a JSON-based syntax that is similar to the one used by Lucene. You can write the query directly and pass it as a string to `search_pv()`:

```{r}
library(patentsview)

qry_1 <- '{"_gt":{"patent_year":2007}}'
search_pv(query = qry_1, fields = NULL) # This will retrieve a default set of fields
```

...Or you can use the domain specific language (DSL) provided in the `patentsview` package to help you write the query:

```{r}
qry_2 <- qry_funs$gt(patent_year = 2007) # All DSL functions are in the qry_funs list
qry_2 # qry_2 is the same as qry_1

search_pv(query = qry_2)
```

`qry_1` and `qry_2` will result in the same HTTP call to the API. Both queries search for patents in USPTO that were published after 2007. There are three gotchas to look out for when writing a query:

1. **All Fields are now queryable.** The API has 12 endpoints (the default endpoint is "patents"), and each endpoint has its own set of fields that you can filter on. 
2. **Correct data type for field.** If you're filtering on a field in your query, you have to make sure that the value you are filtering on is consistent with the field's data type. For example, `patent_year` has type "integer," so if you pass 2007 as a string then you're going to get an error (`patent_year = 2007` is good, `patent_year = "2007"` is no good). You can find a field's data type in the `fieldsdf` data frame.
3. **Comparison function works with field's data type.** The comparison function(s) that you use (e.g., the greater-than function shown above, `qry_funs$gt()`) must be consistent with the field's data type. For example, you can't use the "contains" function on fields of type "integer" (`qry_funs$contains(patent_year = 2007)` will throw an error). See `?qry_funs` for more details.

In short, use the `fieldsdf` data frame when you write a query and you should be fine. Check out the [writing queries vignette](https://ropensci.github.io/patentsview/articles/writing-queries.html) for more details.

### `fields`

Up until now we have been using the default value for `fields`. This results in the API giving us some small set of default fields. Let's see about retrieving some more fields:

With the original verison of the API we requested patent_average_processing_time and inventor_total_num_patents.  These fields are no longer available from the patents endpoint.

```{r}
search_pv(
  query = qry_funs$gt(patent_year = 2007),
  fields = c("patent_abstract", "inventors_at_grant.name_first")
)
```

The fields that you can retrieve depends on the endpoint that you are hitting. We've been using the "patents" endpoint thus far, so all of these are retrievable: `fieldsdf[fieldsdf$endpoint == "patents", "field"]`. You can also use `get_fields()` to list the retrievable fields for a given endpoint:

```{r}
search_pv(
  query = qry_funs$gt(patent_year = 2007),
  fields = get_fields(endpoint = "patents", groups = c("patents", "inventors_at_grant"))
)
```

## Example

Let's look at a quick example of pulling and analyzing patent data. We'll look at patents from the last ten years that are classified below the [H04L63/00 CPC code](https://worldwide.espacenet.com/classification#!/CPC=H04L63/02). Patents in this area relate to "network architectures or network communication protocols for separating internal from external traffic."[^3] CPC codes offer a quick and dirty way to find patents of interest, though getting a sense of their hierarchy can be tricky.

1. Download the data

```{r}
library(patentsview)

# Write a query:
query <- with_qfuns( # with_qfuns is basically just: with(qry_funs, ...)
  and(
    begins(cpc_current.cpc_subgroup_id = 'H04L63/02'),
    gte(patent_year = 2007)
  )
)

# Create a list of fields:
fields <- c(
  c("patent_number", "patent_year"),
  get_fields(endpoint = "patents", groups = c("assignees_at_grant", "cpc_current"))
)

# TODO: fix this
# the above didn't work - get_fields() didn't return a vector of strings?
fields <- get_fields("patents")

# The API currently throws a 500 error when searching by anyb of the CPC fields so we won't send the query to the API.   Instead, we'll query for 300 patent numbers returned from the original API that matched begins(cpc_subgroup_id = 'H04L63/02')  The sort was by patent_title, hoping that will give a random distribution of patent_years (does that matter?)

# Send HTTP request to API's server:   
# pv_res <- search_pv(query = query, fields = fields, all_pages = TRUE)

# When the API is fixed, we'll remove this and make the commented out query above.
# This just lets us move on to see what other changes we have to make to live
# under the new version of the API.

dat <- c("8955089","7778228","10069797","11184318","11076281","7624431","7649848","8111620","10212133","10944724","7873060","8503332","9774570","9882878","10581737","7120692","7600036","7788404","8341275","9071574"
,"9331992","10397188","6219706","10089480","10963575","10880295","9363290","7475138","7805513","8181258","7853687","9509700","6377577","7023853","9749328","9794262","9584482","9712491","7054944","10764299"
,"9154459","9225687","9467932","6233618","10225152","10666651","11115224","10318745","9077688","7937669","9197668","6484258","10798105","8582574","10091209","10581863","9686289","9628458","9912666","8126972"
,"7508767","6697806","7743158","9491625","10834136","9306943","9344296","10958662","10389722","8938794","9537755","10491633","9189644","9529989","9536070","9558334","8082579","10356619","8621570","9137231"
,"9949118","10623450","10681547","10805800","7698452","8688970","9240945","9514294","10049078","7251824","9525740","10798560","10050949","7653200","10911406","10567482","11115465","10171590","9560142","9344426"
,"8806040","10951421","10523445","9756135","10608990","11075999","8782393","9742806","7856508","10885165","7490350","10455449","8505077","10924513","10079839","10616244","10958769","8205240","10505894","10498583"
,"10171425","6550012","7451489","7454499","7454792","7499412","8079075","8447039","7743155","9098459","10594029","8644206","9167426","9398453","10079754","10616279","11005816","9843622","11122065","8205259"
,"8448247","10498752","10235627","8489534","9684867","10425317","8406119","9170902","9674067","7912856","9306913","9660963","7774402","8639846","10362106","11019143","10326734","10616249","6185606","9288236"
,"10389760","10110553","9426121","11032733","6606710","11048770","11190488","10110627","10333827","7904941","8316226","7369537","10911490","8363549","9112911","9935980","10644951","7209486","10469529","8667170"
,"10284504","8463938","10855644","11201847","5654985","10897459","7827313","8069469","8347353","8732796","9356836","9876822","9912701","7478420","7526800","10230531","10764065","6584508","9780995","9392015"
,"9654489","11036867","7533172","9825975","10205743","10645115","11171984","9578052","8464330","10044882","7480937","9094366","9413907","9781280","6785819","10652213","10826916","6349336","10740134","10701104"
,"7065042","10320688","8787875","8595479","9210131","10511573","7418504","7921211","7945654","8554899","8572247","8868705","9037713","9077694","9374346","9967240","6502135","6618761","6907473","7010604"
,"7133930","7933990","7996539","8516117","8874771","9479426","9860283","6985942","8769608","8050281","9542830","9450919","10999318","10630509","11057243","11018995","10785115","8695079","10938619","8230493"
,"11157598","8707406","10986555","10681064","10367703","10931468","9407662","9065846","10749886","9769187","10102019","10289858","8244745","8694523","9152774","10652254","8990259","9514246","10595360","10021108"
,"11012409","11005872","9497206","10986067","10911335","10623283","10992675","9813438","10277606","9942240","10375111","9031539","6738808","7069319","7418503","8041817","8402117","8645505","9571958","10305693"
)

query <- qry_funs$eq("patent_number" = dat)

pv_res <- search_pv(query=query, method="POST", fields = fields, all_pages = TRUE)

```

2. See where the patents are coming from (geographically) 

```{r}
library(leaflet)
library(htmltools)
library(dplyr)
library(tidyr)
library(stringr)

# my mom was an English teacher, so below we singularize/pluralize Patents
# or maybe Patents:1 was ok?

data <-
  pv_res$data$patents %>%
    unnest(assignees_at_grant) %>%
    mutate(assignee_id = as.integer(str_extract(assignee, "(\\d+)(?=/$)"))) %>%
    select(assignee_id, organization, patent_number,
           longitude, latitude) %>%
    group_by_at(vars(-matches("pat"))) %>%
    mutate(num_pats = n()) %>%
    ungroup() %>%
    select(-patent_number) %>%
    distinct() %>%
    mutate(popup = paste0("<font color='Black'>",
                          htmlEscape(organization), "<br><br>Patent",
                          ifelse(num_pats==1, ":", "s:"), # singular/plural
                          num_pats, "</font>")) %>%
    filter_at(vars(latitude,longitude),any_vars(!is.na(.)))  # seeing NA lats and longs

leaflet(data) %>%
  addProviderTiles(providers$CartoDB.DarkMatterNoLabels) %>%
  addCircleMarkers(lng = ~longitude, lat = ~latitude,
                   popup = ~popup, ~sqrt(num_pats), color = "yellow")

```

<br>

3. Plot the growth of the field's topics over time

```{r}
library(ggplot2)
library(RColorBrewer)

# In the new version of the API, we don't get the title back from the patents endpoint
# we have to call, you guessed it, the cpc_subgroup endpoint now
qry <- qry_funs$text_any(cpc_subgroup_id = 'H04L63/02')
qry

# TODO: fix the mapping - seems we want to use _begins here
qry <- '{"_begins":{"cpc_subgroup_id":"H04L63/02"}}'

cpc_info <- search_pv(query=qry, fields = get_fields("cpc_subgroups"), endpoint = "cpc_subgroups")

# More API craziness, in the HATEAS link from the patents endpoint, the separator is 
# inexplicably a colon.  In the data that comes back from the cpc_subgroups endpoint, the 
# separator is, get this, a slash like it should be.  All that to say that joining 
# becomes a bit problematic or an exercise that makes dplyr wonder what we're up to.

data <-
  pv_res$data$patents %>%
    unnest(cpc_current) %>%
    mutate(cpc_subgroup = str_extract(cpc_subgroup, "([\\w:]+)(?=/$)")) %>% # unHATEOAS cpc_subgroup, funky colon and all
    filter(cpc_subgroup != "H04L63:02") %>% # remove patents categorized into only top-level category of H04L63/02
    mutate(cpc_subgroup = str_replace(cpc_subgroup, ":", "/"))  %>%  # back to normality, ahead of a join
    inner_join(cpc_info$data$cpc_subgroups, by=c("cpc_subgroup"="cpc_subgroup_id")) %>%  # highlighting name inconsistency
    ungroup() %>%
    mutate(
      title = case_when(
        grepl("filtering", .$cpc_subgroup_title, ignore.case = T) ~
          "Filtering policies",
        .$cpc_subgroup %in% c("H04L63/0209", "H04L63/0218") ~  
          "Architectural arrangements",
        grepl("Firewall traversal", .$cpc_subgroup_title, ignore.case = T) ~
          "Firewall traversal",
        TRUE ~
          .$cpc_subgroup_title
      )
    ) %>%
    mutate(title = gsub(".*(?=-)-", "", title, perl = TRUE)) %>%
    group_by(title, patent_year) %>%
    count() %>%
    ungroup()

# Here the line graph looks a bit anemic since our data set was only 300 patents and
# the y scale was limits = c(0, 700)).

ggplot(data = data) +
  geom_smooth(aes(x = patent_year, y = n, colour = title), se = FALSE) +
  scale_x_continuous("\nGrant year", limits = c(2007, 2016),
                     breaks = 2007:2016) +
  scale_y_continuous("Patents\n", limits = c(0, 25)) +
  scale_colour_manual("", values = brewer.pal(5, "Set2")) +
  theme_bw() + # theme inspired by https://hrbrmstr.github.io/hrbrthemes/
  theme(panel.border = element_blank(), axis.ticks = element_blank())

```

## Learning more

For analysis examples that go into a little more depth, check out the [data applications vignettes](https://ropensci.github.io/patentsview/articles/citation-networks.html) on the package's website. If you're just interested in `search_pv()`, there are [examples](https://ropensci.github.io/patentsview/articles/examples.html) on the site for that as well. To contribute to the package or report an issue, check out the [issues page on GitHub](https://github.com/ropensci/patentsview/issues).

## Acknowledgments

I'd like to thank the package's two reviewers, [Paul Oldham](https://github.com/poldham) and [Verena Haunschmid](http://blog.haunschmid.name/), for taking the time to review the package and providing helpful feedback. I'd also like to thank [MaÃ«lle Salmon](http://www.masalmon.eu/) for shepherding the package along the rOpenSci review process, as well [Scott Chamberlain](https://scottchamberlain.info/) and [Stefanie Butland](https://twitter.com/stefaniebutland) for their miscellaneous help.

[^1]: This is both good and bad, as there are errors in the disambiguation. The algorithm that is responsible for the disambiguation was created by the winner of the [PatentsView Inventor Disambiguation Technical Workshop](http://www.patentsview.org/workshop/).
[^2]: These two parameters end up getting translated into a MySQL query by the API's server, which then gets sent to a back-end database. `query` and `fields` are used to create the query's `WHERE` and `SELECT` clauses, respectively.
[^3]: There is a slightly more in-depth definition that says that these are patents "related to the (logical) separation of traffic/(sub-) networks to achieve protection." 
