---
title: "Top assignees"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Top assignees}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  comment = "#>", 
  warning = FALSE,
  message = FALSE
)
```

> Note about the affect of the api change
>
> This would be a good example of life under the new api, where we have to make more than one call to get the same data as before.  Maybe even keep the old page around for comparison? 
>
> Intention  
> Alarmingly, application date or year isn't available from any of the new version of the api's endpoints.  Instead we'll use patent_year (the year the patent was granted, already of type integer).  Trouble is that the count is nested inside the patents structure, not inside the nested assignees_at_grant.  Fortunately both nested structures have patent_number as a field so we can join them to get the data we need.
>
> We start by calling the patent endpoint to get the patents where "databases" is in the title or abstract and there is an assignee. We make a subsequent call to the assignee endpoint to get num_patents (total number of patents) for the top 75 assignees, then we blend in the num_patents and compute the percentages. Then life, and the script, goes on as normal (as the old one did). 

The following is a quick analysis of the top organizations patenting in the field of databases.

1. The first step is to download the relevant data fields from the PatentsView API:

```{r}
library(patentsview)
library(dplyr)
library(highcharter)
library(DT)
library(knitr)
library(stringr)

# With the recent api change that limits the overall result set size, we now look
# for databases (plural) where we used to use the singular database for this vignette.
# We also exclude patents without an assignee organization.

# We first need to write a query. Our query will look for "databases" in either 
# the patent title or abstract...Note, this isn't a terribly good way to ID our 
# patents, but it will work for the purpose of demonstration. Users who are 
# interested in writing higher-quality queries could consult the large body of 
# research that has been done in field of patent document retrieval.
query <- with_qfuns(
  and(
     neq("assignees_at_grant.organization" = ""),
     or(
       text_phrase(patent_abstract = "databases"),
       contains(patent_title = "databases")
     )
   )
)

query

# Create a list of the fields we'll need for the analysis

fields <- c(
  "patent_number", "patent_date","patent_year",
  "patent_num_us_patents_cited",
  "assignees_at_grant.organization",  # full text field now if used in q:
  "assignees_at_grant.assignee_id"  # the assignee fields come back in a nested object
)

# Send an HTTP request to the PatentsView API to get the data
pv_out <- search_pv(query, fields = fields, all_pages = TRUE, per_page = 1000)

```

2. Now let's identify who the top assignees are based on how many patents they have in our data set. We'll also calculate how many total patents these assignees have and what fraction of their total patents relate to databases.

```{r}
# Unnest the data frames that are stored in the assignee list column
dl <- unnest_pv_data(pv_out$data, "patent_number")
dl

# We shouldn't need the filter (we queried for non empty string orginazations) but
# some are NA somehow

# We don't get the assignee_total_num_patents back from the patents endpoint any longer.
# We'll have to make a call to the assignee endpoint once we know who the top 75
# assignees are.

# Requested assignees_at_grant.assignee_id comes back in the assignees_at_grant object 
# with key "assignee" and value like https://search.patentsview.org/api/v1/assignee/35/
# We want to parse out the assignee_ids (35 in the example value)
# str_extract(assignee, "(\\d+)(?=/$)")

# Create a data frame with the top 75 assignees:
top_asgns <-
  dl$assignees_at_grant %>%
    filter(!is.na(organization)) %>% # some patents are assigned to an inventor (not an org)
    mutate(assignee_id = str_extract(assignee, "(\\d+)(?=/$)")) %>%
    group_by(organization, assignee_id) %>% 
    summarise(db_pats = n()) %>% 
    ungroup() %>%
    arrange(desc(db_pats)) %>%
    slice(1:75)

# Now that we have the assignee_id's we can call the assignee endpoint to get the
# total number of patents for each of our top_asgns 

# Here it might be convenient to have a qry_funs$member_of for the api's array eq,
# thinking the api might not like 75 or'ed conditions (thought it did work when I tried it)
# The _eq is the safer option.  
#s = toString(as.integer(top_asgns$assignee_id))
#assignee_query = paste('{"assignee_id":[',s,']}')

assignee_query =  qry_funs$eq(assignee_id = as.integer(top_asgns$assignee_id))

assignee_fields <- c(
  "assignee_id","organization", "num_patents" 
)

# we'll post to the api, the query is pretty large if we use qry_funs$eq
assignee_out <- search_pv(assignee_query , fields = assignee_fields, all_pages = TRUE, 
   per_page = 1000, endpoint = "assignees", method = "POST")

assignee_counts <- unnest_pv_data(assignee_out$data, "assignee_id")
assignee_counts

# Here we redo top_asgns now that we have all the fields we need.
# We join in the total counts and mutate in the percentages 
top_asgns <- dl$assignees_at_grant %>%
   inner_join(assignee_counts$assignees) %>%
   rename(ttl_pats = num_patents) %>%
   group_by(organization, ttl_pats) %>%
   summarise(db_pats = n()) %>% 
   mutate(frac_db_pats = round(db_pats / ttl_pats, 3)) %>%
   select(c(1, 3, 2, 4))  %>%
   arrange(desc(db_pats))

# Create datatable
datatable(
  data = top_asgns,
  rownames = FALSE,
  colnames = c(
    "Assignee", "DB patents","Total patents", "DB patents / total patents"
  ),
  caption = htmltools::tags$caption(
    style = 'caption-side: top; text-align: left; font-style: italic;',
    "Table 1: Top assignees in 'databases'"
  ),
  options = list(pageLength = 10)
)
```

<br>

IBM is far and away the biggest player in the field. However, we can see that Oracle and Salesforce.com are relatively more interested in this area, as indicated by the fraction of their patents that relate to databases.

3. Let's see how these assignees' level of investment in databases has changed over time.

```{r}

# The patent endpoint no longer returns application date as this page used originally
# Instead we will use the patent_year  (year the patent was granted, returned as an integer)

# Get the top 5 organizations since slice wasn't working out in the full_join below.
# We want data to just be the top 5 assignees, not all 75 assignees
top_five <- head(top_asgns, n = 5)
   
data <- 
   full_join(dl$assignees_at_grant, dl$patents) %>%
   group_by(organization, patent_year) %>%
   summarise(n = n()) %>%
   inner_join(top_five) %>%
   select(organization,patent_year,n)

# Plot the data using highchartr:
hchart(
  data, "line", 
  hcaes(x = patent_year, y = n, group = organization)
) %>%
  hc_plotOptions(series = list(marker = list(enabled = FALSE))) %>%
  hc_xAxis(title = list(text = "Grant year")) %>%
  hc_yAxis(title = list(text = "Patents")) %>%
  hc_title(text = "Top five assignees in 'databases'") %>%
  hc_subtitle(text = "Yearly granted patents over time")
```

It's hard to see any clear trends in this graph. What is clear is that the top assignees have all been patenting in the field for many years.

4. Finally, let's see how the organizations compare in terms of their citation rates. First, we'll need to normalize the raw citation counts by publication year, so that older patents don't have an unfair advantage over younger patents (i.e., because they have had a longer time to accumulate citations).

```{r}
# Write a ranking function that will be used to rank patents by their citation counts
percent_rank2 <- function(x)
  (rank(x, ties.method = "average", na.last = "keep") - 1) / (sum(!is.na(x)) - 1)

# Create a data frame with normalized citation rates and stats from Step 2
asng_p_dat <-
  dl$patents %>%
  # mutate(patent_yr = substr(patent_date, 1, 4)) %>%
    group_by(patent_year) %>%
    mutate(perc_cite = percent_rank2(patent_num_us_patents_cited)) %>%
    inner_join(dl$assignees) %>%
    group_by(organization) %>%
    summarise(mean_perc = mean(perc_cite)) %>%
    inner_join(top_asgns) %>%
    arrange(desc(ttl_pats)) %>%
    slice(1:20) %>%
    mutate(color = "#f1c40f") %>%
    as.data.frame()

kable(head(asng_p_dat), row.names = FALSE)
```

Now let's visualize the data. Each assignee will be represented by a point/bubble. The x-value of the point will represent the total number of patents the assignee has published in the field of databases (on a log scale), while the y-value will represent its average normalized citation rate. The size of the bubble will be proportional to the percent of the assignee's patents that relate to databases.

```{r}
# Adapted from http://jkunst.com/highcharter/showcase.html
hchart(
  asng_p_dat, "scatter", 
  hcaes(x = db_pats, y = mean_perc, size = frac_db_pats, 
        group = organization, color = color)
) %>%
  hc_xAxis(
    title = list(text = "DB patents"), type = "logarithmic",
    allowDecimals = FALSE, endOnTick = TRUE
  ) %>%
  hc_yAxis(title = list(text = "Mean cite perc.")) %>%
  hc_title(text = "Top assignees in 'databases'") %>%
  hc_add_theme(hc_theme_flatdark()) %>%
  hc_tooltip(
    useHTML = TRUE, pointFormat = tooltip_table(
    x = c("DB patents", "Mean cite percentile", "Fraction DB patents"),
    y = c("{point.db_pats:.0f}","{point.mean_perc:.2f}", "{point.frac_db_pats:.3f}")
  )) %>%
  hc_legend(enabled = FALSE)
```

<br>

It looks like Microsoft has relatively high values across all three three metrics (average citation percentile, number of database patents, and percent of total patents that are related to databases). IBM has more patents than Microsoft, but also has a lower average citation percentile.
